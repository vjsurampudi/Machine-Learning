{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset and creating the IV and DV\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1       2   3   4        5  6  7  8        9\n",
       "0     619   France  Female  42   2        0  1  1  1   101349\n",
       "1     608    Spain  Female  41   1  83807.9  1  0  1   112543\n",
       "2     502   France  Female  42   8   159661  3  1  0   113932\n",
       "3     699   France  Female  39   1        0  2  0  0  93826.6\n",
       "4     850    Spain  Female  43   2   125511  1  1  1  79084.1\n",
       "...   ...      ...     ...  ..  ..      ... .. .. ..      ...\n",
       "9995  771   France    Male  39   5        0  2  1  0  96270.6\n",
       "9996  516   France    Male  35  10  57369.6  1  1  1   101700\n",
       "9997  709   France  Female  36   7        0  1  0  1  42085.6\n",
       "9998  772  Germany    Male  42   3  75075.3  2  1  0  92888.5\n",
       "9999  792   France  Female  28   4   130143  1  1  0  38190.8\n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling categorical or text data\n",
    "\n",
    "Dummy variable trap - Reference link: https://medium.com/datadriveninvestor/dummy-variable-trap-c6d4a387f10a\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Country column\n",
    "ct = ColumnTransformer([(\"Geography\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "# Male/Female\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 4] = labelencoder_X.fit_transform(X[:, 4])\n",
    "\n",
    "X = X[:, 1:] ## Removing one column to avoid dummy variable trap - remove one column from number of categorical values to remove collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1    2  3   4   5        6  7  8  9        10\n",
       "0     0  0  619  0  42   2        0  1  1  1   101349\n",
       "1     0  1  608  0  41   1  83807.9  1  0  1   112543\n",
       "2     0  0  502  0  42   8   159661  3  1  0   113932\n",
       "3     0  0  699  0  39   1        0  2  0  0  93826.6\n",
       "4     0  1  850  0  43   2   125511  1  1  1  79084.1\n",
       "...  .. ..  ... ..  ..  ..      ... .. .. ..      ...\n",
       "9995  0  0  771  1  39   5        0  2  1  0  96270.6\n",
       "9996  0  0  516  1  35  10  57369.6  1  1  1   101700\n",
       "9997  0  0  709  0  36   7        0  1  0  1  42085.6\n",
       "9998  1  0  772  1  42   3  75075.3  2  1  0  92888.5\n",
       "9999  0  0  792  0  28   4   130143  1  1  0  38190.8\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1), (10000, 11))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).shape, pd.DataFrame(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Doing Feature scaling of columns before train test split. \n",
    "This will ensure that the mean and standard deviation for standard scaling (x-mean)/std.deviation is done based on entire dataset.\n",
    "If the step is done after train test split, scaled values might differ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scalaing the columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X= sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the appropriate classes from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding of parameters\n",
    "input_dim = number of variables in input layer - will be taken from dataset if not specified; only for first hidden layer\n",
    "\n",
    "One Thumbrule (not strict): start with average number of inputs from input layer and output layer; in this case 11 (input columns) and 1 output column; number of nodes = (11 + 1)/2 = 6\n",
    "\n",
    "Used sigmoid activation function as the probability of churn is helpful to make a decision\n",
    "\n",
    "loss function - binary_crossentropy since the output variable is binary. if the output is categorical, loss function can be categorical_crossentropy\n",
    "\n",
    "Reference: https://gombru.github.io/2018/05/23/cross_entropy_loss/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers to our ANN\n",
    "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 11))\n",
    "\n",
    "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = \"relu\"))\n",
    "classifier.add(Dense(units = 6, kernel_initializer = \"uniform\", activation = \"relu\"))\n",
    "\n",
    "classifier.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "\n",
    "classifier.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 163\n",
      "Trainable params: 163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz, pydot\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/' ## Install graphviz directly instead of pip\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(classifier, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.5613 - accuracy: 0.7852 - val_loss: 0.4840 - val_accuracy: 0.7975\n",
      "Epoch 2/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8013 - val_loss: 0.4434 - val_accuracy: 0.7975\n",
      "Epoch 3/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7874 - val_loss: 0.4381 - val_accuracy: 0.7975\n",
      "Epoch 4/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7971 - val_loss: 0.4452 - val_accuracy: 0.7975\n",
      "Epoch 5/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7966 - val_loss: 0.4440 - val_accuracy: 0.7975\n",
      "Epoch 6/35\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7975 - val_loss: 0.4460 - val_accuracy: 0.7975\n",
      "Epoch 7/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7886 - val_loss: 0.4430 - val_accuracy: 0.7975\n",
      "Epoch 8/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7964 - val_loss: 0.4457 - val_accuracy: 0.7975\n",
      "Epoch 9/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7978 - val_loss: 0.4587 - val_accuracy: 0.7975\n",
      "Epoch 10/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7935 - val_loss: 0.4459 - val_accuracy: 0.7975\n",
      "Epoch 11/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7918 - val_loss: 0.4393 - val_accuracy: 0.7975\n",
      "Epoch 12/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7937 - val_loss: 0.4459 - val_accuracy: 0.7975\n",
      "Epoch 13/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7930 - val_loss: 0.4400 - val_accuracy: 0.7975\n",
      "Epoch 14/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7995 - val_loss: 0.4434 - val_accuracy: 0.7975\n",
      "Epoch 15/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8024 - val_loss: 0.4560 - val_accuracy: 0.7975\n",
      "Epoch 16/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7943 - val_loss: 0.4524 - val_accuracy: 0.7975\n",
      "Epoch 17/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7912 - val_loss: 0.4477 - val_accuracy: 0.7975\n",
      "Epoch 18/35\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7900 - val_loss: 0.4440 - val_accuracy: 0.7975\n",
      "Epoch 19/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7932 - val_loss: 0.4420 - val_accuracy: 0.7975\n",
      "Epoch 20/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7936 - val_loss: 0.4363 - val_accuracy: 0.7975\n",
      "Epoch 21/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7925 - val_loss: 0.4410 - val_accuracy: 0.7975\n",
      "Epoch 22/35\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7882 - val_loss: 0.4377 - val_accuracy: 0.7975\n",
      "Epoch 23/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8009 - val_loss: 0.4393 - val_accuracy: 0.7975\n",
      "Epoch 24/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7949 - val_loss: 0.4390 - val_accuracy: 0.7975\n",
      "Epoch 25/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7953 - val_loss: 0.4366 - val_accuracy: 0.7975\n",
      "Epoch 26/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7906 - val_loss: 0.4321 - val_accuracy: 0.7975\n",
      "Epoch 27/35\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7939 - val_loss: 0.4329 - val_accuracy: 0.7975\n",
      "Epoch 28/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7990 - val_loss: 0.4513 - val_accuracy: 0.7975\n",
      "Epoch 29/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8022 - val_loss: 0.4342 - val_accuracy: 0.8255\n",
      "Epoch 30/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8124 - val_loss: 0.4279 - val_accuracy: 0.8230\n",
      "Epoch 31/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.4444 - val_accuracy: 0.8240\n",
      "Epoch 32/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8132 - val_loss: 0.4402 - val_accuracy: 0.8295\n",
      "Epoch 33/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8258 - val_loss: 0.4604 - val_accuracy: 0.8290\n",
      "Epoch 34/35\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8152 - val_loss: 0.4359 - val_accuracy: 0.8250\n",
      "Epoch 35/35\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8234 - val_loss: 0.4245 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16875773040>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Training the ANN\n",
    "#Fitting the training-set into the ANN\n",
    "#classifier.fit(X_train, y_train, batch_size = 32, epochs = 35)\n",
    "## If the evaluation should be done with the test data at the end of each epoch, \n",
    "classifier.fit(X_train, y_train, batch_size = 32, epochs = 35, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the test-set\n",
    "y_pred =  classifier.predict(X_test)\n",
    "y_pred = (y_pred >=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = classifier.output_shape ## Number of nodes in output layer\n",
    "b = classifier.input_shape ## number of nodes in input layer\n",
    "c= classifier.optimizer\n",
    "d = classifier.weights ## 6 weights for 11 nodes (11 X 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 1),\n",
       " (None, 11),\n",
       " <tensorflow.python.keras.optimizer_v2.adam.Adam at 0x16875366d90>,\n",
       " [<tf.Variable 'dense_4/kernel:0' shape=(11, 6) dtype=float32, numpy=\n",
       "  array([[-8.3023019e-02, -6.9046967e-02, -5.5079643e-02, -1.7957720e-01,\n",
       "          -7.0419624e-02, -1.0440028e-01],\n",
       "         [-4.8916567e-02, -6.4819038e-02, -4.4164952e-02,  5.5968117e-02,\n",
       "           5.1811155e-02, -4.3265242e-03],\n",
       "         [ 6.7078364e-03,  4.1826829e-02,  2.1990856e-04, -3.2745846e-02,\n",
       "           4.3472689e-02,  4.6416268e-02],\n",
       "         [ 1.9802016e-03,  4.9690507e-02,  1.6197275e-02,  3.3250783e-02,\n",
       "           4.3479200e-02,  3.9020702e-01],\n",
       "         [-4.8531672e-01, -4.4098231e-01, -4.2284948e-01, -3.7379429e-01,\n",
       "           3.5682580e-01, -2.6244268e-01],\n",
       "         [ 3.4799952e-02, -5.4022908e-05,  3.2554492e-02, -5.6802709e-02,\n",
       "           6.4404927e-02,  6.2776148e-02],\n",
       "         [ 9.0347230e-03,  5.3980950e-02, -1.5459101e-02, -1.1896611e-01,\n",
       "          -6.1676097e-03, -2.8685704e-01],\n",
       "         [ 1.9684097e-02, -4.0545701e-03,  2.8420646e-02,  3.3610146e-02,\n",
       "          -2.2617223e-02,  8.4869348e-02],\n",
       "         [ 8.2770997e-04,  8.4108710e-02, -3.0260056e-02, -1.7881456e-01,\n",
       "           1.1179637e-01,  1.5054834e-02],\n",
       "         [-1.6694796e-01, -1.2012738e-01, -1.3235159e-01,  2.7334278e-02,\n",
       "           8.3403188e-01,  3.7949283e-02],\n",
       "         [ 5.2249446e-03,  6.5579884e-02, -1.9189371e-02, -1.3605139e-01,\n",
       "          -7.0784851e-03,  8.6395301e-02]], dtype=float32)>,\n",
       "  <tf.Variable 'dense_4/bias:0' shape=(6,) dtype=float32, numpy=\n",
       "  array([0.62504673, 0.5498021 , 0.5365848 , 0.49266678, 0.24602962,\n",
       "         0.34158477], dtype=float32)>,\n",
       "  <tf.Variable 'dense_5/kernel:0' shape=(6, 6) dtype=float32, numpy=\n",
       "  array([[ 0.34465566,  0.38885996,  0.4269353 ,  0.00165102,  0.3790332 ,\n",
       "           0.44904625],\n",
       "         [ 0.34784153,  0.39587915,  0.32527807,  0.00159397,  0.32791597,\n",
       "           0.41746452],\n",
       "         [ 0.32963726,  0.32449898,  0.3053908 , -0.04001959,  0.3465587 ,\n",
       "           0.36002082],\n",
       "         [ 0.22095871,  0.3227936 ,  0.23949473, -0.01916176,  0.30717903,\n",
       "           0.33849606],\n",
       "         [ 0.5411212 ,  0.5256614 ,  0.58413714, -0.01810399,  0.5359162 ,\n",
       "           0.54712564],\n",
       "         [ 0.20061818,  0.28686196,  0.25918916, -0.04255462,  0.30192074,\n",
       "           0.33097568]], dtype=float32)>,\n",
       "  <tf.Variable 'dense_5/bias:0' shape=(6,) dtype=float32, numpy=\n",
       "  array([-0.10758977, -0.10653172, -0.10538255, -0.01638892, -0.10628789,\n",
       "         -0.10221086], dtype=float32)>,\n",
       "  <tf.Variable 'dense_6/kernel:0' shape=(6, 6) dtype=float32, numpy=\n",
       "  array([[ 0.00824177,  0.32229465,  0.02363257,  0.37534922,  0.324591  ,\n",
       "           0.38296524],\n",
       "         [-0.01482189,  0.3498466 ,  0.01886653,  0.3308349 ,  0.37185478,\n",
       "           0.35607216],\n",
       "         [ 0.01738758,  0.39138559,  0.00363242,  0.3325171 ,  0.4188797 ,\n",
       "           0.41978425],\n",
       "         [-0.01501244, -0.04635993, -0.026355  ,  0.00893198, -0.02633069,\n",
       "           0.0526957 ],\n",
       "         [-0.00653659,  0.40002874, -0.01291652,  0.30916098,  0.38986173,\n",
       "           0.33073986],\n",
       "         [-0.02770645,  0.41118914, -0.04203826,  0.35852253,  0.3899227 ,\n",
       "           0.3172576 ]], dtype=float32)>,\n",
       "  <tf.Variable 'dense_6/bias:0' shape=(6,) dtype=float32, numpy=\n",
       "  array([-0.00775197, -0.09475574, -0.00724192, -0.08710402, -0.09479169,\n",
       "         -0.09017629], dtype=float32)>,\n",
       "  <tf.Variable 'dense_7/kernel:0' shape=(6, 1) dtype=float32, numpy=\n",
       "  array([[ 0.03419488],\n",
       "         [-0.330108  ],\n",
       "         [ 0.00424219],\n",
       "         [-0.33037788],\n",
       "         [-0.36761898],\n",
       "         [-0.35316396]], dtype=float32)>,\n",
       "  <tf.Variable 'dense_7/bias:0' shape=(1,) dtype=float32, numpy=array([0.8975139], dtype=float32)>])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1556,   39],\n",
       "       [ 282,  123]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8395"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = (1556 + 123)/2000\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning using GridSearch\n",
    "\n",
    "Reference: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
